# Q-Learning Configuration

# Environment settings
environment:
  type: "default"  # "simple" or "default"
  grid_size: [5, 5]
  start_position: [0, 0]
  goal_position: [4, 4]
  obstacles: [[1, 1], [2, 2], [3, 1]]
  max_steps: 50
  reward_structure:
    goal: 10.0
    step: -0.1
    obstacle: -1.0
    out_of_bounds: -1.0

# Agent settings
agent:
  learning_rate: 0.1
  discount_factor: 0.9
  epsilon: 0.1
  epsilon_decay: 0.995
  epsilon_min: 0.01

# Training settings
training:
  num_episodes: 1000
  eval_frequency: 100
  eval_episodes: 100
  verbose: true

# Reproducibility
seed: 42

# Output settings
output:
  save_model: true
  save_plots: true
  log_level: "INFO"
  output_dir: "data/logs"
